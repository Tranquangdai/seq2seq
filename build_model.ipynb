{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, LSTMCell\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "from generate_uncorrect_sample import generate_misspell_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define class for creating and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_pred, y):\n",
    "    log_loss = SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "    loss = log_loss(y_true=y, y_pred=y_pred)\n",
    "    \n",
    "    mask = tf.logical_not(tf.math.equal(y, 0)) # output 0 for y=0 else output 1\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss = mask * loss\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "def generate_pair_samples(w):\n",
    "    w_gen = list(generate_misspell_sample(w, max_edit_distance=2))\n",
    "    return list(zip(w_gen, [w]*len(w_gen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text2Seq(object):\n",
    "    \n",
    "    def __init__(self, charset, \n",
    "                 start_token='<s>',\n",
    "                 end_token='<e>',\n",
    "                 unknown_token='<unk>'):\n",
    "        \n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.unk_token = unknown_token\n",
    "        if isinstance(charset, str):\n",
    "            with open(charset, 'r+') as f:\n",
    "                self.charset = set(f.read().split('\\n'))\n",
    "        else:\n",
    "            self.charset = charset\n",
    "        self.charset += [' ', self.start_token, self.end_token, self.unk_token]\n",
    "        self.charset = set(self.charset)\n",
    "        self.charset_size = len(self.charset)\n",
    "        \n",
    "        self.char2id = {j: i for i, j in enumerate(self.charset, start=1)}\n",
    "        self.id2char = {j: i for i, j in self.char2id.items()}\n",
    "        \n",
    "    def _encode(self, word, max_len, pad_start_end):\n",
    "        padded = []\n",
    "        for c in word:\n",
    "            padded.append(self.char2id.get(c, self.char2id[self.unk_token]))\n",
    "        if pad_start_end:\n",
    "            padded = [self.char2id[self.start_token]] + padded + [self.char2id[self.end_token]]\n",
    "            padded += (max_len + 2 - len(padded)) * [0]\n",
    "        else:\n",
    "            padded += (max_len - len(padded)) * [0]\n",
    "        return padded\n",
    "    \n",
    "    def fit_on_texts(self, texts, pad_start_end=False):\n",
    "        max_len = self.get_max_seq_len(texts)\n",
    "        \n",
    "        arr = []\n",
    "        for word in texts:\n",
    "            arr.append(self._encode(word, max_len, pad_start_end))\n",
    "        return np.array(arr, dtype=np.int8)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_max_seq_len(texts):\n",
    "        return max(len(word) for word in texts)\n",
    "    \n",
    "    def sequence_to_text(self, arr, remove_endtoken=False):\n",
    "        def _inside(arr):\n",
    "            word = []\n",
    "            for i in arr:\n",
    "                if i!=0:\n",
    "                    if remove_endtoken:\n",
    "                        if i==self.char2id.get(self.end_token):\n",
    "                            break\n",
    "                    word.append(self.id2char.get(i, self.unk_token))\n",
    "            return ''.join(word)\n",
    "        \n",
    "        result = []\n",
    "        for a in arr:\n",
    "            result.append(_inside(a))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "correct_words = ['có thể', 'thế giới', 'con người', 'không thể', 'tất cả', 'chúng ta']\n",
    "for w in correct_words:\n",
    "    pairs.extend(generate_pair_samples(w))\n",
    "df = pd.DataFrame(pairs, columns=['misspell', 'correct']).sample(frac=1, random_state=123)\n",
    "charset = list(set(''.join(df.misspell.values+df.correct.values)))\n",
    "\n",
    "text2seq = Text2Seq(charset)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text2seq.fit_on_texts(df.misspell.values), \n",
    "                                                    text2seq.fit_on_texts(df.correct.values, pad_start_end=True), \n",
    "                                                    test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "BUFFER_SIZE = len(X_train)\n",
    "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE\n",
    "embedding_dims = 64\n",
    "rnn_units = dense_units = 64\n",
    "\n",
    "Tx = X_train.shape[1]\n",
    "Ty = Y_train.shape[1]\n",
    "\n",
    "input_vocab_size = output_vocab_size = text2seq.charset_size+1\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    \n",
    "    def __init__(self, input_vocab_size=None, embedding_dims=128, rnn_units=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_embedding = Embedding(input_vocab_size, embedding_dims)\n",
    "        self.encoder_birnn = Bidirectional(LSTM(rnn_units, return_sequences=True, dropout=0.2))\n",
    "        self.encoder_stackrnn = LSTM(rnn_units, return_sequences=True, return_state=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.encoder_embedding(inputs)\n",
    "        x = self.encoder_birnn(x)\n",
    "        x = self.encoder_stackrnn(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(Model):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 output_vocab_size=None, \n",
    "                 embedding_dims=128, \n",
    "                 rnn_units=64, \n",
    "                 dense_units=64, \n",
    "                 batch_size=128,\n",
    "                 encoder_max_seq_len=None,\n",
    "                 decoder_max_seq_len=None,\n",
    "                 start_token=None,\n",
    "                 end_token=None,\n",
    "                 beam_width=5,\n",
    "                 training=True):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoder_max_seq_len = decoder_max_seq_len\n",
    "        \n",
    "        self.decoder_embedding = Embedding(output_vocab_size, embedding_dims)\n",
    "        self.dense_layer = Dense(output_vocab_size)\n",
    "        self.rnn_cell = LSTMCell(rnn_units)\n",
    "        \n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.beam_width = beam_width\n",
    "        self.training = training\n",
    "        \n",
    "        # training phase\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "        self.attn_mech = tfa.seq2seq.LuongAttention(dense_units, \n",
    "                                                    None, \n",
    "                                                    self.batch_size * [encoder_max_seq_len])\n",
    "        self.attn_cell = tfa.seq2seq.AttentionWrapper(self.rnn_cell,\n",
    "                                                     self.attn_mech,\n",
    "                                                     dense_units)\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.attn_cell, self.sampler, self.dense_layer)\n",
    "\n",
    "    def set_decoder_memory_and_initialState(self, memory, batch_size, encoder_state):\n",
    "        self.attn_mech.setup_memory(memory)\n",
    "        decoder_initial_state = self.attn_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
    "        decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
    "        return decoder_initial_state\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        d_in, encoder_outputs, state_h, state_c = inputs\n",
    "        \n",
    "        if self.training:\n",
    "            decoder_emb = self.decoder_embedding(d_in)\n",
    "\n",
    "            decoder_initial_state = self.set_decoder_memory_and_initialState(encoder_outputs, \n",
    "                                                                             self.batch_size, \n",
    "                                                                             [state_h, state_c])\n",
    "            outputs, _, _ = self.decoder(decoder_emb, \n",
    "                                         initial_state=decoder_initial_state, \n",
    "                                         sequence_length=self.batch_size * [self.decoder_max_seq_len - 1])\n",
    "            logits = outputs.rnn_output\n",
    "            return logits\n",
    "        else:\n",
    "            inference_batch_size = 1\n",
    "            _ = self.decoder_embedding(d_in)\n",
    "            encoder_state_beam = tfa.seq2seq.tile_batch([state_h, state_c], self.beam_width)\n",
    "            encoder_outputs_beam = tfa.seq2seq.tile_batch(encoder_outputs, self.beam_width)\n",
    "\n",
    "            decoder_initial_state = self.set_decoder_memory_and_initialState(encoder_outputs_beam, \n",
    "                                                                             inference_batch_size*self.beam_width, \n",
    "                                                                             encoder_state_beam)\n",
    "            decoder_instance = tfa.seq2seq.BeamSearchDecoder(self.attn_cell, \n",
    "                                                             beam_width=self.beam_width, \n",
    "                                                             output_layer=self.dense_layer)\n",
    "\n",
    "            start_tokens = tf.fill([inference_batch_size], self.start_token)\n",
    "            end_token = self.end_token\n",
    "            _, inputs, state = decoder_instance.initialize(self.decoder_embedding.variables[0] ,\n",
    "                                                         start_tokens=start_tokens,\n",
    "                                                         end_token=end_token,\n",
    "                                                         initial_state=decoder_initial_state)\n",
    "            \n",
    "            beam_ids = []\n",
    "            beam_scores = []\n",
    "            for j in range(self.decoder_max_seq_len):\n",
    "                beam_output, state, inputs, _ = decoder_instance.step(j, inputs, state)\n",
    "                beam_ids.append(beam_output.predicted_ids)\n",
    "                beam_scores.append(beam_output.scores)\n",
    "            return beam_ids, beam_scores\n",
    "\n",
    "class EncoderDecoder():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_vocab_size=None,\n",
    "                 output_vocab_size=None, \n",
    "                 embedding_dims=128, \n",
    "                 rnn_units=64, \n",
    "                 dense_units=64, \n",
    "                 batch_size=128,\n",
    "                 encoder_max_seq_len=None,\n",
    "                 decoder_max_seq_len=None,\n",
    "                 start_token=None,\n",
    "                 end_token=None,\n",
    "                 beam_width=5,\n",
    "                 training=None):\n",
    "        \n",
    "        self.start_token = start_token\n",
    "        self.batch_size = batch_size\n",
    "        self.training = training\n",
    "        \n",
    "        self.encoder = Encoder(input_vocab_size=input_vocab_size, \n",
    "                               embedding_dims=embedding_dims, \n",
    "                               rnn_units=rnn_units)\n",
    "        self.decoder = Decoder(output_vocab_size=output_vocab_size, \n",
    "                                embedding_dims=embedding_dims, \n",
    "                                rnn_units=rnn_units, \n",
    "                                dense_units=dense_units, \n",
    "                                batch_size=batch_size,\n",
    "                                encoder_max_seq_len=encoder_max_seq_len,\n",
    "                                decoder_max_seq_len=decoder_max_seq_len,\n",
    "                                start_token=start_token,\n",
    "                                end_token=end_token,\n",
    "                                beam_width=beam_width,\n",
    "                                training=training\n",
    "                              )\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        # encode phase\n",
    "        e_in, d_in = inputs\n",
    "        e_out, state_h, state_c = self.encoder(e_in)\n",
    "        # decode phase\n",
    "        return self.decoder([d_in, e_out, state_h, state_c])\n",
    "            \n",
    "    def compile(self, optimizer, loss=None, metrics=None):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    def _step(self, x_batch, y_batch):\n",
    "        d_in = y_batch[:, :-1]  # ignore <end>\n",
    "        d_out = y_batch[:, 1:]  # ignore <start>\n",
    "\n",
    "        logits = self([x_batch, d_in])\n",
    "        loss = self.loss_fn(logits, d_out)\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, x_batch, y_batch):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._step(x_batch, y_batch)\n",
    "        vars_ = self.encoder.trainable_variables + self.decoder.trainable_variables # be careful\n",
    "        grads = tape.gradient(loss, vars_)\n",
    "        self.optimizer.apply_gradients(zip(grads, vars_))\n",
    "        return loss\n",
    "    \n",
    "    def fit(self, train_dataset, epochs=1, eval_dataset=None):\n",
    "        num_train_samples = tf.data.experimental.cardinality(train_dataset).numpy() * self.batch_size\n",
    "        for epoch in range(epochs):\n",
    "            print(\"\\nepoch {}/{}\".format(epoch+1,epochs))\n",
    "            pbar = tf.keras.utils.Progbar(num_train_samples, stateful_metrics=['train_loss'])\n",
    "\n",
    "            for i, (x_batch, y_batch) in enumerate(train_dataset):\n",
    "                train_loss = self.train_step(x_batch, y_batch)\n",
    "                values = [('train_loss', train_loss)]\n",
    "                pbar.update(i*self.batch_size, values=values)\n",
    "\n",
    "            if eval_dataset is not None:\n",
    "                for x_batch, y_batch in test_dataset:\n",
    "                    val_loss = self._step(x_batch, y_batch)\n",
    "                values=[('train_loss',train_loss),('val_loss',val_loss)]\n",
    "            else:\n",
    "                values=[('train_loss',train_loss)]\n",
    "            pbar.update(num_train_samples, values=values)\n",
    "            \n",
    "    def save_weights(self, path):\n",
    "        self.encoder.save_weights(join(path, 'encoder_weights.h5'))\n",
    "        self.decoder.save_weights(join(path, 'decoder_weights.h5'))\n",
    "        \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, \n",
    "                         path, \n",
    "                         input_vocab_size,\n",
    "                         output_vocab_size, \n",
    "                         embedding_dims, \n",
    "                         rnn_units, \n",
    "                         dense_units, \n",
    "                         batch_size,\n",
    "                         encoder_max_seq_len,\n",
    "                         decoder_max_seq_len,\n",
    "                         start_token,\n",
    "                         end_token,\n",
    "                         beam_width,\n",
    "                         training):\n",
    "        \n",
    "        model = cls(input_vocab_size,\n",
    "                     output_vocab_size, \n",
    "                     embedding_dims, \n",
    "                     rnn_units, \n",
    "                     dense_units, \n",
    "                     batch_size,\n",
    "                     encoder_max_seq_len,\n",
    "                     decoder_max_seq_len,\n",
    "                     start_token,\n",
    "                     end_token,\n",
    "                     beam_width,\n",
    "                     training)\n",
    "        model.encoder.build((None, None))\n",
    "        model.encoder.load_weights(join(path, 'encoder_weights.h5'))\n",
    "        model.decoder.build([(None, None), (None, None, rnn_units), (None, rnn_units), (None, rnn_units)])\n",
    "        model.decoder.load_weights(join(path, 'decoder_weights.h5'))\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def decode_prediction(outputs):\n",
    "        beam_ids, beam_scores = outputs\n",
    "        return np.array([i.numpy() for i in beam_ids]).squeeze().transpose()\n",
    "    \n",
    "    def predict(self, input_ids):\n",
    "        beam_outputs = self([input_ids, np.array([[self.start_token]])])\n",
    "        return self.decode_prediction(beam_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token=text2seq.char2id.get('<s>')\n",
    "end_token=text2seq.char2id.get('<e>')\n",
    "\n",
    "model = EncoderDecoder(input_vocab_size,\n",
    "                         output_vocab_size, \n",
    "                         embedding_dims, \n",
    "                         rnn_units, \n",
    "                         dense_units, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         encoder_max_seq_len=Tx,\n",
    "                         decoder_max_seq_len=Ty,\n",
    "                         start_token=start_token,\n",
    "                         end_token=end_token,\n",
    "                         beam_width=5,\n",
    "                         training=True)\n",
    "lr_schedule = tfa.optimizers.ExponentialCyclicalLearningRate(initial_learning_rate=5e-4, \n",
    "                                                              maximal_learning_rate=1e-2,\n",
    "                                                              step_size=steps_per_epoch*2, \n",
    "                                                              scale_mode=\"cycle\", \n",
    "                                                              gamma=0.96)\n",
    "opt = tfa.optimizers.Lookahead(tf.keras.optimizers.Adam(clipnorm=3.0, learning_rate=lr_schedule))\n",
    "model.compile(optimizer=opt, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/40\n",
      "108/108 [==============================] - 9s 82ms/step - train_loss: 2.2956 - val_loss: 2.2727\n",
      "\n",
      "epoch 2/40\n",
      "108/108 [==============================] - 1s 13ms/step - train_loss: 1.8667 - val_loss: 1.7295\n",
      "\n",
      "epoch 3/40\n",
      "108/108 [==============================] - 1s 10ms/step - train_loss: 0.7807 - val_loss: 0.5903\n",
      "\n",
      "epoch 4/40\n",
      "108/108 [==============================] - 1s 9ms/step - train_loss: 0.3975 - val_loss: 0.4281\n",
      "\n",
      "epoch 5/40\n",
      "108/108 [==============================] - 1s 9ms/step - train_loss: 0.1496 - val_loss: 0.2347\n",
      "\n",
      "epoch 6/40\n",
      "108/108 [==============================] - 1s 10ms/step - train_loss: 0.1413 - val_loss: 0.12530.0\n",
      "\n",
      "epoch 7/40\n",
      "108/108 [==============================] - 1s 11ms/step - train_loss: 0.0353 - val_loss: 0.03190.\n",
      "\n",
      "epoch 8/40\n",
      "108/108 [==============================] - 1s 9ms/step - train_loss: 0.0278 - val_loss: 0.0345\n",
      "\n",
      "epoch 9/40\n",
      "108/108 [==============================] - 1s 7ms/step - train_loss: 0.0176 - val_loss: 0.0157\n",
      "\n",
      "epoch 10/40\n",
      "108/108 [==============================] - 1s 9ms/step - train_loss: 0.0083 - val_loss: 0.0125\n",
      "\n",
      "epoch 11/40\n",
      "108/108 [==============================] - 1s 11ms/step - train_loss: 0.0057 - val_loss: 0.0186\n",
      "\n",
      "epoch 12/40\n",
      "108/108 [==============================] - 1s 9ms/step - train_loss: 0.0051 - val_loss: 0.0074\n",
      "\n",
      "epoch 13/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 0.0051 - val_loss: 0.0046\n",
      "\n",
      "epoch 14/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 0.0035 - val_loss: 0.0191\n",
      "\n",
      "epoch 15/40\n",
      "108/108 [==============================] - 1s 7ms/step - train_loss: 0.0029 - val_loss: 0.0028\n",
      "\n",
      "epoch 16/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 0.0026 - val_loss: 0.0038\n",
      "\n",
      "epoch 17/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 0.0025 - val_loss: 0.0188\n",
      "\n",
      "epoch 18/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 0.0017 - val_loss: 0.0022\n",
      "\n",
      "epoch 19/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 0.0021 - val_loss: 0.0159 0.0\n",
      "\n",
      "epoch 20/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 0.0018 - val_loss: 0.0025 0.0\n",
      "\n",
      "epoch 21/40\n",
      "108/108 [==============================] - 1s 9ms/step - train_loss: 0.0018 - val_loss: 0.0164\n",
      "\n",
      "epoch 22/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 0.0013 - val_loss: 0.0023\n",
      "\n",
      "epoch 23/40\n",
      "108/108 [==============================] - 1s 7ms/step - train_loss: 0.0014 - val_loss: 0.0016\n",
      "\n",
      "epoch 24/40\n",
      "108/108 [==============================] - 1s 11ms/step - train_loss: 0.0011 - val_loss: 0.0018\n",
      "\n",
      "epoch 25/40\n",
      "108/108 [==============================] - 1s 10ms/step - train_loss: 0.0012 - val_loss: 0.0016\n",
      "\n",
      "epoch 26/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 0.0012 - val_loss: 0.0013\n",
      "\n",
      "epoch 27/40\n",
      "108/108 [==============================] - 1s 7ms/step - train_loss: 7.4981e-04 - val_loss: 0.0151\n",
      "\n",
      "epoch 28/40\n",
      "108/108 [==============================] - 1s 7ms/step - train_loss: 0.0012 - val_loss: 8.2995e-04\n",
      "\n",
      "epoch 29/40\n",
      "108/108 [==============================] - 1s 7ms/step - train_loss: 8.5101e-04 - val_loss: 0.0150\n",
      "\n",
      "epoch 30/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 7.4658e-04 - val_loss: 8.9822e-04\n",
      "\n",
      "epoch 31/40\n",
      "108/108 [==============================] - 1s 11ms/step - train_loss: 7.1353e-04 - val_loss: 0.0012\n",
      "\n",
      "epoch 32/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 7.2834e-04 - val_loss: 0.0011\n",
      "\n",
      "epoch 33/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 6.6460e-04 - val_loss: 9.8646e-04\n",
      "\n",
      "epoch 34/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 6.9714e-04 - val_loss: 0.0125\n",
      "\n",
      "epoch 35/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 8.4883e-04 - val_loss: 9.1470e-04\n",
      "\n",
      "epoch 36/40\n",
      "108/108 [==============================] - 1s 7ms/step - train_loss: 6.4236e-04 - val_loss: 0.0124\n",
      "\n",
      "epoch 37/40\n",
      "108/108 [==============================] - 1s 8ms/step - train_loss: 6.1812e-04 - val_loss: 7.3320e-04\n",
      "\n",
      "epoch 38/40\n",
      "108/108 [==============================] - 1s 9ms/step - train_loss: 4.9017e-04 - val_loss: 6.6418e-04\n",
      "\n",
      "epoch 39/40\n",
      "108/108 [==============================] - 1s 7ms/step - train_loss: 7.5460e-04 - val_loss: 0.0104\n",
      "\n",
      "epoch 40/40\n",
      "108/108 [==============================] - 1s 7ms/step - train_loss: 5.2944e-04 - val_loss: 0.0112\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=40, eval_dataset=test_dataset)\n",
    "model.save_weights('model/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and do inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = EncoderDecoder.from_pretrained('model/1',\n",
    "                         input_vocab_size,\n",
    "                         output_vocab_size, \n",
    "                         embedding_dims, \n",
    "                         rnn_units, \n",
    "                         dense_units, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         encoder_max_seq_len=Tx,\n",
    "                         decoder_max_seq_len=Ty,\n",
    "                         start_token=start_token,\n",
    "                         end_token=end_token,\n",
    "                         beam_width=5,\n",
    "                         training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['có thể', 'tấúna', 'kh  ả', 'óấtng ta', 'ờó cc']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = text2seq.fit_on_texts(['cơ the'])\n",
    "text2seq.sequence_to_text(loaded_model.predict(inputs), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chúng ta', 'ko ngưca', 'tón n ta', 'hh tagờa', 'ờnế g']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = text2seq.fit_on_texts(['chng ta'])\n",
    "text2seq.sequence_to_text(loaded_model.predict(inputs), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['có thể', 'tấ ng ta', 'khúna', 'óấúng ta', 'ờtt g ta']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = text2seq.fit_on_texts(['taast cả'])\n",
    "text2seq.sequence_to_text(loaded_model.predict(inputs), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['không thể', 'chúng ta', 'thông thể', 'ôhông th', 'ểókng thể']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = text2seq.fit_on_texts(['khongtheer'])\n",
    "text2seq.sequence_to_text(loaded_model.predict(inputs), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
